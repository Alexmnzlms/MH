\chapter{Experimentos y análisis de resultados}
\section{Semillas}
%Descripción de los casos del problema empleados y de los valores de los parámetros considerados en las ejecuciones de cada algoritmo (incluyendo las semillas utilizadas).
Para la ejecución de los algoritmos se han seleccionado las siguientes semillas, utilizando un algoritmo para probar que no producen ciclos en ninguna de las ejecuciones del algoritmo greedy para ninguno de los conjuntos de datos. Toda semilla que en menos de 1000 iteraciones del algoritmo greedy no obtenga resultado es rechazada. \\
Las semillas se han cambiado respecto a la práctica anterior debido al cambio de conjuntos de datos:
\begin{itemize}
   \item 2024614690
   \item 2024676296
   \item 2024677261
   \item 2024740484
   \item 2024740899
\end{itemize}


El código utilizado para encontrar semillas se encuentra en la función \textbf{buscar\_semilla()} que se incluye en el fichero main.cpp


\section{Análisis}
%Análisis de resultados. El análisis deberá estar orientado a justificar (según el comportamiento de cada algoritmo) los resultados obtenidos en lugar de realizar una mera “lectura” de las tablas. Se valorará la inclusión de otros elementos de comparación tales como gráficas de convergencia, boxplots, análisis comparativo de las soluciones obtenidas, representación gráfica de las soluciones, etc.
Este análisis se va a estructurar en 3 partes. En primer lugar comentaré los resultados de los data sets de Iris y Rand. Estos se comentan en un mismo apartado debido a la gran similitud que existe entre ellos. Posteriormente se analizarán los resultados del data set Ecoli, que más complejidad y dificultad en el ajuste presenta, con clara diferencia. Por último se analizarán los resultados del nuevo data set, Newthyroid, que si bien presenta la misma estructura de clasificación que Iris y Rand, supone un aumento en la dificultad de computo respecto a estos. Ya que tanto los data sets como las semillas se han modificado, se han repetido las ejecuciones para los algoritmos greedy y de búsqueda local.

\subsection{Iris \& Rand}
Los data sets de Iris y Rand, no presentan ninguna dificultad para los algoritmos genéticos y meméticos. Como podemos observar en la Tabla 6.10, todos los algortimos implementados en esta práctica consiguen converger a la solución óptima, tanto para Rand como para Iris con 10\% y 20\% de restricciones. Si bien es cierto, el algoritmo que peor ajuste realiza es el algoritmo greedy, pero como ya comentamos, el algoritmo greedy depende en gran medida de la colocación inicial de los centroides en el espacio de datos. Una buena colocación inicial nos ayuda a obtener una mejor solución.
\\
Estos conjuntos son perfectos para ajustar el funcionamiento de los algoritmos genéticos y meméticos. Sus cromosomas no poseen una longitud excesiva y solo cuenta con 3 clusters para la clasificación. Esto facilita que el límite de iteraciones (100000) sea más que suficiente para que las poblaciones de cromosomas converjan a una solución óptima.

\subsection{Ecoli}
El data set Ecoli si que presenta un reto a la hora de obtener una solución optima. Con un numero mayor de clusters y de genes por cromosoma, el límite de evaluaciones puede quedarse corto si estas no se optimizan de la mejor manera posible. Cuantas menos evaluaciones redundantes seamos capaces de eliminar, más generaciones podrá alcanzar el algortimo genético o memético y mejores soluciones aportará. Esta dificultad añadida al computo se puede notar en que el tiempo necesario para agotar las evaluaciones en el data set Ecoli es 5 veces mayor que el necesario en los data sets Rand e Iris.
\\
Tomando como referencia ---tanto para 10\% de restricciones como para 20\%--- los algoritmos greedy y de búsqueda local, todos los algoritmos genéticos y meméticos mejoran la solución aportada por estos dos, siendo el algoritmo greedy el que mejores soluciones aporta. Esto se puede deber a una buena colocación de los centroides iniciales.
\\
También podemos apreciar que existen diferencias entre los algoritmos genéticos y meméticos. Estos últimos aportan mejores soluciones, lo que no es de extrañar, ya que a grandes rasgos se trata de un AGG\_UN al que se le aplica una BLS.
Entre el modelo generacional y el modelo estacionario, no podemos apreciar grandes diferencias en los resultados. Aunque si notar que para el modelo generacional, el operador que mejor resultado aporta es el operador de cruce uniforme, mientras que para el modelo estacionario, el operador que encuentra una mejor solución es el operador de cruce por segmento fijo.
Esto podría explicarse porque, en el modelo generacional, al reemplazar a todos los individuos en cada generación, se favorece la exploración del espacio de soluciones ---mientra que el operador de segmento fijo, al estar sesgado, favorece la exploración de las soluciones--- permitiendo encontrar mejores optimos. Para el modelo estacionario, al solo seleccionar a dos cromosomas cada generación, el operador de segmento fijo, explota a estos dos cromosomas, de manera que converjan a una mejor solución, en detrimento de una mayor exploración del espacio de cromosomas.
\\
Entre los algoritmos memeticos, encontramos que para un 10\% de restricciones, la mejor solucion la aporta AM\_10-0.1 y para un 20\% la aporta AM\_10-0.1 mej.
Estos dos meméticos, realizan la BLS a un 10\% de la poblacion, por lo que podemos notar que eso es suficiente para encontrar buenas soluciones. AM\_10-0.1 es el algoritmo más costoso, debido a que realiza una mayor cantidad de BLS. A la vista de los resultados, tantas BLS no significan una mejora en los resultados. Si bien, AM\_10-1.0 mejora a los algortimos genéticos en los que se basa, con aplicar la BLS a solo un 10\% es suficiente para encontrar las mismas o mejores soluciones.


\subsection{Newthyroid}
