\chapter{Experimentos y análisis de resultados}
\section{Semillas}
%Descripción de los casos del problema empleados y de los valores de los parámetros considerados en las ejecuciones de cada algoritmo (incluyendo las semillas utilizadas).
Para la ejecución de los algoritmos se han seleccionado las siguientes semillas, utilizando un algoritmo para probar que no producen ciclos en ninguna de las ejecuciones del algoritmo greedy para ninguno de los conjuntos de datos. Toda semilla que en menos de 1000 iteraciones del algoritmo greedy no obtenga resultado es rechazada. \\
Las semillas se han cambiado respecto a la práctica anterior debido al cambio de conjuntos de datos:
\begin{itemize}
   \item 2024614690
   \item 2024676296
   \item 2024677261
   \item 2024740484
   \item 2024740899
\end{itemize}


El código utilizado para encontrar semillas se encuentra en la función \textbf{buscar\_semilla()} que se incluye en el fichero main.cpp


\section{Análisis}
%Análisis de resultados. El análisis deberá estar orientado a justificar (según el comportamiento de cada algoritmo) los resultados obtenidos en lugar de realizar una mera “lectura” de las tablas. Se valorará la inclusión de otros elementos de comparación tales como gráficas de convergencia, boxplots, análisis comparativo de las soluciones obtenidas, representación gráfica de las soluciones, etc.
Al igual que en la práctica anterior, dividiré el análisis de los resultados de los algoritmos en los distintos conjuntos. Esta vez analizaré \emph{Iris} y \emph{Rand} separado de \emph{Ecoli} y \emph{Newthyroid} ya que los primeros son conjuntos en bastantes simples y los segundos presentan más batalla a la hora de encontrar una buena solución.

\subsection{Iris \& Rand}
A la vista de los resultados obtenidos, puedo afirmar que los conjuntos de \emph{Iris} y \emph{Rand} no presentan ninguna dificultad para los algoritmos a la hora de encontrar una solución `optima'. Podemos ver que las soluciones de todos los algoritmos convergen a la solución `optima' (excepto en el algoritmo greedy, cosa que ya comentamos en las prácticas anteriores).\\
Este resultado no es de extrañar, ya que todos los algoritmos implementados en esta práctica surgen como modificación o adaptación de alguna forma de la búsqueda local clásica y puesto que este algoritmo aporta soluciones que convergen a un `optimo', lógicamente las modificaciones para mejorar la exploración del espacio de búsqueda no deberían afectar a esta capacidad de la búsqueda local.


\subsection{Ecoli \& Newthyroid}
A diferencia de los conjuntos de \emph{Iris} y \emph{Rand} que son conjuntos prácticamente de prueba, para ver que los algoritmos funcionen correctamente,
\emph{Newthyroid} y sobre todo \emph{Ecoli} si que presentan un reto a la hora de encontrar una solución `optima' al problema de la asignación con restricciones.\\
Para empezar podemos apreciar que tanto para las restricciones del 10\% como para las del 20\% los algoritmos de BMB, ES e ILS mejoran las soluciones aportadas por la BL y por greedy. Esto tiene sentido, puesto que BMB se basa en realizar una serie de búsquedas locales desde puntos de partida distintos, por lo que evitamos estancarnos en un mínimo local y obtener mejores soluciones, ES añade un componente de diversificación inicial de la solución que permite obtener soluciones muy diversas al principio y empezar a explotar la más prometedora con el paso de las iteraciones y finalmente ILS se basa en realizar varias BL al igual que la BMB pero con la diferencia de que a la mejor solución encontrada se le aplica un operador de mutación en cada iteración que permite diversificar la solución lo suficiente como para evitar los mínimos locales. Como se puede observar todas estas técnicas aportan buenas soluciones, siendo ILS el algoritmo que mejor resultados aporta para ambos conjuntos de restricciones (para \emph{Ecoli} porque para \emph{Newthyroid} los tres algoritmos convergen a la misma solución).
\\
El algoritmo que presenta un problema es ILS-ES (Iterated Local Search con Enfriamiento Simulado) y esto no es más que una consecuencia del número de iteraciones máximo con el que se realiza cada ES dentro de la ILS. Al ser ES un algoritmo para el que número de iteraciones juega un papel decisivo, puesto que las iteraciones deben ser las suficientes para que la temperatura descienda correctamente, nos encontramos ante un caso de iteraciones máximas insuficientes, puesto que con solo 10000 iteraciones, al algoritmo ES no le da tiempo a enfriar la temperatura lo suficiente como para abandonar la fase de diversificación y comenzar la fase de explotación de la solución. Por este motivo, los ES realizados en la ILS-ES diversifican mucho las soluciones al inicio pero no llegan a la fase de explotación de las mismas, aportando las soluciones tan nefastas que podemos ver.


\subsection{Conclusión}
Como conclusión, salvo por el algoritmo de ILS-ES y su problema con el número de iteraciones máximas, vemos que los algoritmos de BMB, ES e ILS, obtienen unos resultados muy buenos, llegando a superar a algunos de los algoritmos genéticos y meméticos de la práctica anterior.
